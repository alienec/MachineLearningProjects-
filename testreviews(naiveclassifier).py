# -*- coding: utf-8 -*-
"""TestReviews(NaiveClassifier).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/140KjfPfxrdzeggk9QEGqheigiOTLQ4L9
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import re
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.naive_bayes import MultinomialNB
from wordcloud import WordCloud
# %matplotlib inline

test_review = pd.read_csv("TestReviews.csv", engine="python")
test_review.head()

test_review.shape



from nltk.corpus import stopwords
nltk.download("stopwords")
from textwrap import fill
print(fill(', '.join(stopwords.words("english")), width = 80))
stop = stopwords.words("english")
test_review['review'] = test_review["review"].apply(lambda x: ' '. join([item for item in x.split() if item not in stop]))

X = test_review["review"]
y = test_review["class"]

def clean_text(doc):
  document = re.sub('[^a-zA-Z]', ' ', doc)
  document = re.sub(r"\s+[a-zA-z]\s+", ' ', document)
  document = re.sub(r"\s+", ' ', document)
  return document

X_sentences = []
reviews = list(X)
for rev in reviews:
  X_sentences.append(clean_text(rev))

from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=2500, min_df=5, max_df=0.7, stop_words = stopwords.words('english'))
X = vectorizer.fit_transform(X_sentences).toarray()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

spam_detector = MultinomialNB()
spam_detector.fit(X_train, y_train)

y_pred = spam_detector.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))

print(X_sentences[56])
print(y[56])