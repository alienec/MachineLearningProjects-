# -*- coding: utf-8 -*-
"""DimensionalityReductionProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e6QSBNcqEBCgxnFZYBhiUog9pAqxN1Dp
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib as plt
import matplotlib.pyplot as plt

from sklearn.datasets import load_breast_cancer
data = load_breast_cancer()
df = pd.DataFrame(data=data.data, columns=data.feature_names)
df['target'] = data.target
df.columns = df.columns.str.lower().str.replace(" ", "_")
df.head()

plt.xlabel('Worst Area')
plt.ylabel('Worst_Smoothness')
plt.title('Worst Area vs Worst Smoothness')
plt.bar(df['worst_area'], df['worst_smoothness'])

"""### PCA with Breast Cancer"""

X = df.drop(["target"], axis=1)
y = df["target"]

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
y = le.fit_transform(y)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

#apply scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#import PCA class
from sklearn.decomposition import PCA
#create class of PCA
pca = PCA()
#training PCA model on training data
X_train = pca.fit_transform(X_train)
#make predictions on test data
X_test = pca.transform(X_test)

variance_ratios = pca.explained_variance_ratio_
print(variance_ratios)

from sklearn.decomposition import PCA
pca = PCA(n_components=2) #attribute of PCA given a specific value
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression()
classifier.fit(X_train, y_train)
#training the logisitic regression model
lg = LogisticRegression()
lg.fit(X_train, y_train)
#predict the test set results
y_pred = lg.predict(X_test)
#evaluate result
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred))

"""The output tells that the accurancy for predicting the whether or not someone has breast cancer is around 92%."""

# Commented out IPython magic to ensure Python compatibility.
from matplotlib import pyplot as plt
# %matplotlib inline
#print actual datapoints
plt.scatter(X_test[:, 0], X_test[:, 1], c= y_test, cmap="rainbow")

"""### LDA with Breast Cancer Dataset"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
#scale the data using StandardScaler()
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
#create the object of the LDA class
lda = LDA()
#training LDA model on training data
X_train = lda.fit_transform(X_train, y_train)
#making prediction based on test data
X_test = lda.transform(X_test)

variance_ratios = lda.explained_variance_ratio_
print(variance_ratios)

lda = LDA(n_components=1)
X_train = lda.fit_transform(X_train, y_train)
X_test = lda.transform(X_test)

lg = LogisticRegression()
lg.fit(X_train, y_train)
y_pred = lg.predict(X_test)
print(accuracy_score(y_test, y_pred))

# Commented out IPython magic to ensure Python compatibility.
from matplotlib import pyplot as plt
# %matplotlib inline
#print actual datapoints
plt.scatter(X_test[:, 0], X_test[:, 0],  c= y_test, cmap="rainbow")

"""LCA of this dataset means that it could accurately predict whether or not the values found in the breast cancer dataset are not true with an accurancy of 97%.

The PCA value was lower than the LDA value indicating that the LDA value had a higher chance of making it correlate and translate better than the PCA value. However, due to both of them indicating that the data has a high correlation, it won't matter within this low stakes context whether or not PCA or LDA had been used. A linear fit would be the best for this type of graph because it had the largest correlation indicating that factors to cause breast cancer are directly proportioal to the accurate predictions for breast cancer.
"""