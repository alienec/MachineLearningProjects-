# -*- coding: utf-8 -*-
"""ActualCNNModelofCreation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QiPK5jmIXGOKqi99VpMG9l6i8loX3GOv
"""

import tensorflow as tf
print(tf.version)

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPool2D
from tensorflow.keras.models import Model
import tensorflow as tf
import numpy as np

dataset_main = "data"

# Load the dataset
dataset = tf.keras.utils.image_dataset_from_directory(
    dataset_main,
    batch_size=32,
    image_size=(128, 128),
    shuffle=True
)

#tells the length of the dataset
size_dataset = len(dataset)
size_train = int(0.8 * size_dataset)

#the training dataset
dataset_train = dataset.take(size_train)
test_dataset = dataset.skip(size_train)

def dataset_to_numpy(dataset):
    images, labels = [], []
    for image_batch, label_batch in dataset:
        images.extend(image_batch.numpy())
        labels.extend(label_batch.numpy())
    return np.array(images), np.array(labels)

#training images
training_images, training_labels = dataset_to_numpy(dataset_train)
#testing images
test_images, test_labels = dataset_to_numpy(test_dataset)

# Check the shapes
print("Training data shape:", training_images.shape, training_labels.shape)
print("Test data shape:", test_images.shape, test_labels.shape)

"""Code Sourced From Medium: https://medium.com/@sssspppp/image-classification-using-cnn-0fad8367acfd"""

#shows the training images
training_images, test_images = training_images/255.0, test_images/255.0
print(training_images.shape)

#shows the training images
plt.figure()
plt.imshow(test_images[9])
plt.colorbar()
plt.grid(False)
plt.show()

#shows the picture of the testing images

#shows the testing images
plt.figure()
plt.imshow(test_images[9])
plt.colorbar()
plt.grid(False)
plt.show()

output_classes = len(np.unique(training_labels))
print("Number of output classes is: ", output_classes)

#made 3 classes

training_images[0].shape

#tells the dimensions of the testing images

input_layer = Input(shape = (128, 128, 3))
conv1 = Conv2D(32, (3,3), strides = 2, activation= 'relu') (input_layer)
maxpool1 = MaxPool2D(2, 2)(conv1)
conv2 = Conv2D(64, (3,3), strides = 2, activation= 'relu') (maxpool1)
flat1 = Flatten()(conv2)
drop1 = Dropout(0.2)(flat1)
dense1 = Dense(512, activation = 'relu')(drop1)
drop2 = Dropout(0.2)(dense1)
output_layer = Dense(output_classes, activation= 'softmax')(drop2)
model = Model(input_layer, output_layer)

#makes the model

model.compile(optimizer = 'adam', loss=
'sparse_categorical_crossentropy', metrics =['accuracy'])
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='model_plot1.png',
show_shapes=True, show_layer_names=True)

#makes the optimizer

model_history = model.fit(training_images, training_labels, epochs=20, validation_data=(test_images, test_labels), verbose=1)

#tells the model history

import matplotlib.pyplot as plt
plt.plot(model_history.history['accuracy'], label='accuracy')
plt.plot(model_history.history['val_accuracy'], label='val_accuracy')
plt.legend(['train','test'], loc='lower left')

#graphs the accuracu

plt.plot(model_history.history['loss'], label = 'loss')
plt.plot(model_history.history['val_loss'], label = 'val_loss')
plt.legend(['train','test'], loc='upper left')

#tells the loss

output = model.predict(test_images)
prediction = np.argmax(output[9])
print(prediction)

#tells the accuracy