# -*- coding: utf-8 -*-
"""MySeq2Seq2Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Blx2MDtTd8u7_es9RTQ864QnYkOM7ejn
"""

import os, sys
from keras.models import Model
from keras.layers import Input, LSTM, GRU, Dense, Embedding
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/gdrive')

input_english_sentences = []
output_french_sentences = []
output_french_sentences_inputs = []

TOTAL_SENTENCES = 50000 # Define TOTAL_SENTENCES

count = 0
for line in open(r'/content/tam.txt', encoding = 'utf-8'): # Corrected file path
  count += 1
  if count > TOTAL_SENTENCES:
    break
  if '\t' not in line:
    continue

  input_sentence = line.rstrip().split('\t')[0] # Corrected variable name to match usage below
  output = line.rstrip().split('\t')[1]

  output_sentence = output + ' <eos>'
  output_sentence_input = '<sos> ' + output

  input_english_sentences.append(input_sentence)
  output_french_sentences.append(output_sentence)
  output_french_sentences_inputs.append(output_sentence_input)

print("sentences in input:", len(input_english_sentences))
print("sentences in output:", len(output_french_sentences))
print("sentences for output input:", len(output_french_sentences_inputs))

print(input_english_sentences[175])
print(output_french_sentences[175])
print(output_french_sentences_inputs[175])

MAX_NUM_WORDS = 20000 # Define MAX_NUM_WORDS
input_eng_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)
input_eng_tokenizer.fit_on_texts(input_english_sentences)
input_eng_integer_seq = input_eng_tokenizer.texts_to_sequences(input_english_sentences)

word2idx_eng_inputs = input_eng_tokenizer.word_index
print('Sum of unique words in English sentences: %s"' %len(word2idx_eng_inputs))

max_input_len = max(len(sen) for sen in input_eng_integer_seq)
print("Length of longest sentence in English sentences: %g" % max_input_len)

output_french_tokenizer = Tokenizer(num_words = MAX_NUM_WORDS, filters = '')
output_french_tokenizer.fit_on_texts(output_french_sentences+output_french_sentences_inputs)
output_french_integer_seq=output_french_tokenizer.texts_to_sequences(output_french_sentences)
output_input_french_integer_seq=output_french_tokenizer.texts_to_sequences(output_french_sentences_inputs)

word2idx_french_outputs = output_french_tokenizer.word_index
print('Sum of unique words in French sentences: %s' %len(word2idx_french_outputs))

num_words_output = len(word2idx_french_outputs) + 1
max_out_len = max(len(sen) for sen in output_french_integer_seq)

print("Length of longest sentence in French sentences: %g" % max_out_len)

encoder_input_eng_sequences = pad_sequences(input_eng_integer_seq, maxlen=max_input_len)
print("encoder_input_eng_sequences.shape", encoder_input_eng_sequences.shape)
print("encoder_input_eng_sequences[175]", encoder_input_eng_sequences[175])

print(word2idx_eng_inputs["i'm"])

decoder_input_french_sequences = pad_sequences(output_input_french_integer_seq, maxlen=max_out_len, padding = 'post')
print("decoder_input_french_sequences.shape:", decoder_input_french_sequences.shape)
print("decoder_input_french_sequences[175]:", decoder_input_french_sequences[175])

decoder_output_french_sentences = pad_sequences(output_french_integer_seq, maxlen = max_out_len, padding='post')

from numpy import array
from numpy import asarray
from numpy import zeros
embeddings_dictionary = dict()
glove_file = open(r'/content/glove.6B.100d.txt', encoding = 'utf8')


for line in glove_file:
  records = line.split()
  word = records[0]
  vector_dimensions = asarray(records[1:], dtype = 'float32')
  embeddings_dictionary[word] = vector_dimensions

glove_file.close()

EMBEDDING_SIZE = 100 # Define EMBEDDING_SIZE
num_words = min(MAX_NUM_WORDS, len(word2idx_eng_inputs) + 1)
embedding_matrix = zeros((num_words, EMBEDDING_SIZE))
for word, index in word2idx_eng_inputs.items():
  embedding_vector = embeddings_dictionary.get(word)

  if embedding_vector is not None:
    embedding_matrix[index] = embedding_vector

decoder_one_hot_targets = np.zeros((len(input_english_sentences), max_out_len, num_words_output), dtype='float32')

decoder_one_hot_targets.shape

for i, d in enumerate(decoder_output_french_sentences):
  for t, word in enumerate(d):
    decoder_one_hot_targets[i, t, word] = 1

LSTM_NODES = 256 # Define LSTM_NODES
embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], trainable=False)

encoder_inputs_eng_placeholder = Input(shape=(max_input_len, ))
x= embedding_layer(encoder_inputs_eng_placeholder)
encoder = LSTM(LSTM_NODES, return_state=True)

encoder_outputs, h, c = encoder(x)
encoder_states =[h, c]

decoder_inputs_french_placeholder = Input(shape=(max_out_len,))

decoder_embedding = Embedding(num_words_output, LSTM_NODES)
decoder_inputs_x = decoder_embedding(decoder_inputs_french_placeholder)

decoder_lstm = LSTM(LSTM_NODES, return_sequences = True, return_state = True)

decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state = encoder_states)

decoder_dense = Dense(num_words_output, activation='softmax')

decoder_outputs = decoder_dense(decoder_outputs)

model = Model([encoder_inputs_eng_placeholder, decoder_inputs_french_placeholder], decoder_outputs)
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

from keras.utils import plot_model
plot_model(model, to_file = 'model_plot4a.png', show_shapes = True, show_layer_names = True)

BATCH_SIZE = 64 # Define BATCH_SIZE
NUM_EPOCHS = 20 # Define NUM_EPOCHS
r = model.fit(
    [encoder_input_eng_sequences, decoder_input_french_sequences],
    decoder_one_hot_targets,
    batch_size = BATCH_SIZE,
    epochs= NUM_EPOCHS,
    validation_split = 0.1,
  )

encoder_prediction_model = Model(encoder_inputs_eng_placeholder, encoder_states)
decoder_state_input_h = Input(shape=(LSTM_NODES,))
decoder_state_input_c = Input(shape=(LSTM_NODES,))

decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]

decoder_inputs_single = Input(shape=(1,))
decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)

decoder_lstm = LSTM(LSTM_NODES, return_sequences = True, return_state = True)

decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state = decoder_states_inputs)

decoder_states = [h, c]
decoder_outputs = decoder_dense(decoder_outputs)

decoder_model = Model(
    [decoder_inputs_single] + decoder_states_inputs,
    [decoder_outputs] + decoder_states
)

from keras.utils import plot_model
plot_model(model, to_file = 'model_plot4a.png', show_shapes = True, show_layer_names = True)

idx2word_eng_input = {v:k for k, v in word2idx_eng_inputs.items()}
idx2word_french_target={v:k for k, v in word2idx_french_outputs.items()}

def perform_translation(input_seq):
  states = encoder_prediction_model.predict(input_seq)
  target_seq = np.zeros((1, 1))
  target_seq[0, 0] = word2idx_french_outputs['<sos>']
  eos = word2idx_french_outputs['<eos>']
  output_sentence = []

  for _ in range(max_out_len):
    output_tokens, h, c = decoder_model.predict([target_seq]+ states)
    idx = np.argmax(output_tokens[0, 0, :])

    if eos == idx:
      break
    word = ''
    if idx > 0:
      word = idx2word_french_target[idx]
      output_sentence.append(word)

    target_seq[0,0] = idx
    states = [h, c]

  return ' '.join(output_sentence)

random_sentence_index = np.random.choice(len(input_english_sentences))
input_eng_seq = encoder_input_eng_sequences[random_sentence_index:random_sentence_index+1]
translation = perform_translation(input_eng_seq)
print('-')
print('Input Sentence:', input_english_sentences[random_sentence_index])
print('Translated Sentence:', translation)