# -*- coding: utf-8 -*-
"""heart.disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KGuQaHuVRnm0L2TaEvtiPf5OJhX_SyAd
"""

import pandas as pd
import numpy as np
import seaborn as sns

heart = pd.read_csv('heart.csv')

"""Link for the dataset: https://www.kaggle.com/datasets/volodymyrgavrysh/heart-disease"""

heart

heart.describe()

heart = heart.drop_duplicates()
heart = heart.drop(['sex', 'slope', 'ca'], axis=1)

X = heart.drop('target', axis=1)
y = heart['target']

X

y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform (X_test)

heartsnum = pd.concat([X, y], axis=1)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
plt.rcParams["figure.figsize"] = [8,6]
corr = heartsnum.corr()
corr

sns.heatmap(corr)

from sklearn.neighbors import KNeighborsClassifier
knn_clf = KNeighborsClassifier(n_neighbors=5)
classifier = knn_clf.fit(X_train, y_train)
y_pred = classifier.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accurancy: ", accuracy_score(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
rf_cf = RandomForestClassifier(random_state=42, n_estimators=500)
classifier = rf_cf.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accurancy: ", accuracy_score(y_test, y_pred))

from sklearn import svm
svm_clf = svm.SVC()
classifier = svm_clf.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accurancy: ", accuracy_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score
print(cross_val_score(classifier, X, y, cv=5, scoring='accuracy').mean())

heart.loc[105]

from sklearn.ensemble import RandomForestClassifier
rf_cf = RandomForestClassifier(random_state=42, n_estimators=500)
classifier = rf_cf.fit(X_train, y_train)
single_record = sc.transform(X.values[100].reshape(1, -1))
predicted_churn = classifier.predict(single_record)
print(predicted_churn)

from sklearn.linear_model import LogisticRegression
log_clf = LogisticRegression()
classifier = log_clf.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accurancy: ", accuracy_score(y_test, y_pred))

from sklearn.metrics import roc_curve, roc_auc_score

y_pred_prob = rf_cf.predict_proba(X_test)[:,1 ]

fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)

# C o m p u t e t h e R O C A U C s c o r e
roc_auc = roc_auc_score(y_test, y_pred_prob)
roc_auc

plt.plot(fpr, tpr, label = 'ROC curve (are a = % 0.2f) ' % roc_auc)

plt.plot([0 , 1] , [0 , 1], 'k--', label = ' Random classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc = "lower right")
plt.show( )

"""The dataset is called hearts.csv and it measures the chances in which the person is to get heart disease. The x-value or independent values are everything but gender, slope, and number of vessels colored by flourosopy since they are irrelevant and also dropped the target sine it is the dependent variable or the one getting measured. Finding the correlation between these factors and probability of getting the disease, it shows a strong positive correlation between them indicating that the factors are a good indicator of the person getting heart disease. According to the ROC curve, there is a correlation coefficient of 0.92 which is a nearly one to one while the others type of correlation coefficient calculator depict something lower indicating that the other methods of classification are not good for these type of dataset compared to ROC curve. Also since the ROC curve has an coefficient of 0.92, it has more true positives than false positives indicating its reliability in telling how the data is."""