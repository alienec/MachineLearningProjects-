# -*- coding: utf-8 -*-
"""Copy of DNN Project: Predicting Car Prices

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aq2UY0pC2zyce1W-2dFyJaxZ_fNUnlqR
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow.keras.layers import Input, Dense, Dropout, Activation
from tensorflow.keras.models import Model, Sequential

# Import the Dataset
df = pd.read_csv("car_data.csv")

# Print the first five rows
print(df.head())

# Data Preprocessing
# Drop the 'New_Price' and 'Unnamed: 0' columns
df.drop(columns=["New_Price", "Unnamed: 0", "Location", "Fuel_Type", "Transmission", "Owner_Type", "Mileage", "Engine", "Power"], inplace=True)

# Convert Categorical Columns to Numerical
print(df.dtypes)

# Drop the 'Name' column
df.drop(columns=["Name"], inplace=True)

# Separate numerical and categorical columns
numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()

# One-hot encoding for categorical columns
df = pd.get_dummies(df, columns=categorical_cols)

# Visualizations
# Heatmap of numerical column relationships
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Heatmap of Numerical Features")
plt.show()

# Histogram for Price
df["Price"].hist(bins=50, edgecolor='black')
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.title("Price Distribution")
plt.show()

# Remove rows with null values
df.dropna(inplace=True)

# Divide data into features and labels
X = df.drop(columns=["Price"])
y = df["Price"]

# Split dataset into training and testing sets
# Divide Data into Training and Test Sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)

# Scale the Data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Creating Neural Network Model
input_layer = Input(shape=(X.shape[1],))
dense_layer0 = Dense(100, activation='relu')(input_layer)
dense_layer1 = Dense(50, activation='relu')(dense_layer0)
dense_layer2 = Dense(25, activation='relu')(dense_layer1)
dense_layer3 = Dense(10, activation='relu')(dense_layer2)
dense_layer4 = Dense(5, activation='relu')(dense_layer3)
dense_layer5 = Dense(2, activation='relu')(dense_layer4)
output_layer = Dense(1)(dense_layer5)

model = Model(inputs=input_layer, outputs=output_layer)
model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])

# Plot the model structure
from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True, show_layer_names=True)

# Train the model
model.fit(X_train, y_train, epochs=5, batch_size=5, validation_split=0.2)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate model performance
from sklearn import metrics
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))
price_mean = df['Price'].mean()
percentage_error = mae / price_mean

print('Mean Absolute Error:', mae)
print('Mean Squared Error:', mse)
print('Root Mean Squared Error:', rmse)
print('Mean Price:', price_mean)
print('Mean Percentage Error:', percentage_error)

# Compare actual vs predicted prices
comparison_df = pd.DataFrame({'Actual': y_test.values.tolist(), 'Predicted': y_pred.flatten().tolist()})
print(comparison_df)

# Making Predictions on a Single Data Point
single_point = X_test[1].reshape(1,-1)
predicted_price = model.predict(single_point)
actual_price = y_test.values[1]

print('Predicted Price:', predicted_price[0][0])
print('Actual Price:', actual_price)